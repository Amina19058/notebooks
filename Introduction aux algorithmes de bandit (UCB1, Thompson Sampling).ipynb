{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introduction-aux-algorithmes-de-bandit-(UCB1,-Thompson-Sampling)\" data-toc-modified-id=\"Introduction-aux-algorithmes-de-bandit-(UCB1,-Thompson-Sampling)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction aux <em>algorithmes de bandit</em> (UCB1, Thompson Sampling)</a></div><div class=\"lev2 toc-item\"><a href=\"#Problèmes-de-bandit\" data-toc-modified-id=\"Problèmes-de-bandit-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Problèmes de bandit</a></div><div class=\"lev2 toc-item\"><a href=\"#Simulation-de-problèmes-de-bandit\" data-toc-modified-id=\"Simulation-de-problèmes-de-bandit-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Simulation de problèmes de bandit</a></div><div class=\"lev2 toc-item\"><a href=\"#Bras-stochastiques,-de-Bernoulli\" data-toc-modified-id=\"Bras-stochastiques,-de-Bernoulli-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Bras stochastiques, de Bernoulli</a></div><div class=\"lev2 toc-item\"><a href=\"#Présentation-des-algorithmes-de-bandit\" data-toc-modified-id=\"Présentation-des-algorithmes-de-bandit-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Présentation des algorithmes de bandit</a></div><div class=\"lev2 toc-item\"><a href=\"#Deux-algorithmes-naïfs\" data-toc-modified-id=\"Deux-algorithmes-naïfs-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Deux algorithmes naïfs</a></div><div class=\"lev3 toc-item\"><a href=\"#ChoixUniforme\" data-toc-modified-id=\"ChoixUniforme-151\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span><code>ChoixUniforme</code></a></div><div class=\"lev3 toc-item\"><a href=\"#MoyenneEmpirique\" data-toc-modified-id=\"MoyenneEmpirique-152\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span><code>MoyenneEmpirique</code></a></div><div class=\"lev2 toc-item\"><a href=\"#Approche-fréquentiste,-UCB1,-&quot;Upper-Confidence-Bound&quot;\" data-toc-modified-id=\"Approche-fréquentiste,-UCB1,-&quot;Upper-Confidence-Bound&quot;-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Approche fréquentiste, UCB1, \"Upper Confidence Bound\"</a></div><div class=\"lev2 toc-item\"><a href=\"#Approche-bayésienne,-Thompson-Sampling\" data-toc-modified-id=\"Approche-bayésienne,-Thompson-Sampling-17\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Approche bayésienne, Thompson Sampling</a></div><div class=\"lev2 toc-item\"><a href=\"#Exemples-de-simulations\" data-toc-modified-id=\"Exemples-de-simulations-18\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Exemples de simulations</a></div><div class=\"lev3 toc-item\"><a href=\"#Fonctions-pour-l'affichage\" data-toc-modified-id=\"Fonctions-pour-l'affichage-181\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Fonctions pour l'affichage</a></div><div class=\"lev3 toc-item\"><a href=\"#Premier-problème,-à-3-bras\" data-toc-modified-id=\"Premier-problème,-à-3-bras-182\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>Premier problème, à 3 bras</a></div><div class=\"lev3 toc-item\"><a href=\"#Second-problème,-à-10-bras\" data-toc-modified-id=\"Second-problème,-à-10-bras-183\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>Second problème, à 10 bras</a></div><div class=\"lev2 toc-item\"><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-19\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Conclusion</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux *algorithmes de bandit* (UCB1, Thompson Sampling)\n",
    "Ce petit document est un [notebook Jupyter](https://www.jupyter.org), ayant pour but de présenter le concept de problèmes de bandit, comment les simuler et les résoudre, et deux algorithmes conçus dans ce but.\n",
    "\n",
    "Je ne vais pas donner beaucoup d'explications mathématiques, je conseille plutôt [ce petit article, datant de 2017, en français, écrit par Émilie Kaufmann](http://chercheurs.lille.inria.fr/ekaufman/Matapli_Kaufmann.pdf).\n",
    "\n",
    "Je préfère me focaliser sur une implémentation simple, claire et concise de chaque morceau nécessaire à la simulation de problèmes et d'algorithmes de bandit.\n",
    "J'utilise le [langage de programmation Python](https://www.python.org/).\n",
    "\n",
    "Dans ce but, j'utilise une approche *objet* : chaque morceau sera une classe, et des *instances* (des *objets*) seront utilisées pour toutes les composantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dépendances\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Problèmes de bandit\n",
    "\n",
    "FIXME expliquer cette partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Simulation de problèmes de bandit\n",
    "\n",
    "Une simple *fonction* suffira ici, pour initialiser un algorithme, le simuler durant $T$ étapes, et stocker les récompenses et les bras tirés.\n",
    "\n",
    "Il est important de tout stocker pour ensuite pouvoir afficher différentes statistiques sur l'expérience, permettant d'évaluer l'efficacité des différentes algorithmes.\n",
    "\n",
    "Je préfère donner directement cette fonction afin de fixer les *signatures* des différentes classes qu'on va écrire ensuite :\n",
    "\n",
    "- Les *bras* ont besoin d'une seule méthode, `tire()` qui donne $r_k(t) \\sim \\nu_k$ à l'instant $t$ pour la distribution $\\nu_k$ du $k^{\\text{ième}}$ bras, noté `r_k_t`.\n",
    "- Les *algorithmes* ont besoin de trois méthodes :\n",
    "    + `commence()` pour initialiser l'algorithme, une fois,\n",
    "    + `A_t = choix()` pour choisir un bras, à chaque instant $t$, noté $A(t) \\in \\{1,\\dots,K\\}$,\n",
    "    + `recompense(A_t, r_k_t)` pour donner la récompense `r_k_t` tirée du bras `A_t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulation(bras, algorithme, horizon):\n",
    "    \"\"\" Simule l'algorithme donné sur ces bras, durant horizon étapes.\"\"\"\n",
    "    choix, recompenses = np.zeros(horizon), np.zeros(horizon)\n",
    "    # 1. Initialise l'algorithme\n",
    "    algorithme.commence()\n",
    "    # 2. Boucle en temps, pour t = 0 à horizon - 1\n",
    "    for t in range(horizon):\n",
    "        # 2.a. L'algorithme choisi son bras à essayer\n",
    "        A_t = algorithme.choix()\n",
    "        # 2.b. Le bras k donne une récompense\n",
    "        r_k_t = bras[A_t].tire()\n",
    "        # 2.c. La récompense est donnée à l'algorithme\n",
    "        algorithme.recompense(A_t, r_k_t)\n",
    "        # 2.d. On stocke les deux\n",
    "        choix[t] = A_t\n",
    "        recompenses[t] = r_k_t\n",
    "    # 3. On termine en renvoyant ces deux vecteurs\n",
    "    return recompenses, choix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Bras stochastiques, de Bernoulli\n",
    "\n",
    "Les récompenses de tels bras, notées $r_k(t)$ pour le bras $k$ à l'instant $t$, sont tirées de façons identiquement distribuées et indépendantes, selon une loi de Bernoulli :\n",
    "$$ \\forall t\\in\\mathbb{N}, \\forall k\\in\\{1,\\dots,K\\}, r_k(t) \\sim \\mathrm{B}(\\mu_k). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bernoulli():\n",
    "    \"\"\" Bras distribués selon une loi de Bernoulli.\"\"\"\n",
    "\n",
    "    def __init__(self, probabilite):\n",
    "        assert 0 <= probabilite <= 1, \"Erreur, probabilite doit être entre 0 et 1 pour un bras de Bernoulli.\"\n",
    "        self.probabilite = probabilite\n",
    "\n",
    "    def tire(self):\n",
    "        \"\"\" Tire une récompense aléatoire.\"\"\"\n",
    "        return float(rd.random() <= self.probabilite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, on peut considérer le problème à trois bras ($K = 3$), caractérisé par ces paramètres $\\boldsymbol{\\mu} = [\\mu_1,\\dots,\\mu_K] = [0.1, 0.5, 0.9]$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mus = [ 0.1, 0.5, 0.9 ]\n",
    "bras = [ Bernoulli(mu) for mu in mus ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut prendre 10 échantillons de chaque bras, et vérifier leurs moyennes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.seed(10000)\n",
    "T = 10\n",
    "exemples_echantillons = [ [ bras_k.tire() for _ in range(T) ] for bras_k in bras ]\n",
    "exemples_echantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.5,  0.9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(exemples_echantillons, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C'est assez proche de $\\boldsymbol{\\mu} = [\\mu_1,\\dots,\\mu_K] = [0.1, 0.5, 0.9]$... Non ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Présentation des algorithmes de bandit\n",
    "Comme on l'a dit plus haut, les *algorithmes* ont besoin de trois méthodes :\n",
    "\n",
    "- `commence()` pour initialiser l'algorithme, une fois. Généralement, il s'agit de remettre à zero les vecteurs de mémoires internes de l'algorithme, et de mettre $t = 0$.\n",
    "- `A_t = choix()` pour choisir un bras, à chaque instant $t$, noté $A(t) \\in \\{1,\\dots,K\\}$. C'est la partie \"intelligente\" qui doit être conçue avec soin.\n",
    "- `recompense(A_t, r_k_t)` pour donner la récompense `r_k_t` tirée du bras `A_t`. Souvent, il suffit de mettre à jour les deux ou trois vecteurs internes.\n",
    "\n",
    "En fait, il faut aussi une méthode pour *créer* l'instance de la classe, i.e., une méthode `__init__(K)`, qui demande de simplement connaître $K$, le nombre de bras.\n",
    "\n",
    "> Bien-sûr, les algorithmes ne doivent pas connaître $\\boldsymbol{\\mu} = [\\mu_1,\\dots,\\mu_K]$ les paramètres du problème... Sinon l'apprentissage n'a aucun intérêt : il suffit de viser $k^* = \\arg\\max_k \\mu_k$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Deux algorithmes naïfs\n",
    "On va commencer par donner deux exemples naïfs :\n",
    "\n",
    "1. Un algorithme \"stupide\" qui choisi un bras de façon complètement uniforme, $A^{1}(t) \\sim U(1,\\dots,K), \\forall t$, à chaque instant $t \\in \\mathbb{N}$, via la classe `ChoixUniforme`.\n",
    "\n",
    "2. Un algorithme moins stupide, mais assez naïf, qui utilise un *estimateur empirique* $\\widehat{\\mu_k}(t) = \\frac{X_k(t)}{N_k(t)}$ de la *moyenne* de chaque bras, et tire $A^{2}(t) \\in \\arg\\max_k \\widehat{\\mu_k}(t)$ à chaque instant $t \\in \\mathbb{N}$. Ici, $X_k(t) = \\sum_{\\tau=0}^{t} \\mathbb{1}(A(\\tau) = k) r_k(\\tau)$ compte les récompenses *accumulées* en tirant le bras $k$, sur les instants $t = 0,\\dots,\\tau$. Et $N_k(t) = \\sum_{\\tau=0}^{t} \\mathbb{1}(A(\\tau) = k)$ compte le nombre de sélections de ce bras $k$. Via la classe `MoyenneEmpirique`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ChoixUniforme`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChoixUniforme(object):\n",
    "    \"\"\"Algorithme stupide, choix uniforme.\"\"\"\n",
    "    \n",
    "    def __init__(self, K):\n",
    "        \"\"\"Crée l'instance de l'algorithme.\"\"\"\n",
    "        self.K = K\n",
    "    \n",
    "    def commence(self):\n",
    "        \"\"\"Initialise l'algorithme : rien à faire ici.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def choix(self):\n",
    "        \"\"\"Choix uniforme d'un indice A(t) ~ U(1...K).\"\"\"\n",
    "        return rd.randint(0, self.K - 1)\n",
    "        \n",
    "    def recompense(self, k, r):\n",
    "        \"\"\"Donne une récompense r tirée sur le bras k à l'algorithme : rien à faire ici.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MoyenneEmpirique`\n",
    "Voilà qui donne une bonne idée de la structure (*\"API\"*) que vont devoir suivre les différentes algorithmes.\n",
    "\n",
    "L'algorithme suivant est un peu plus complexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoyenneEmpirique(object):\n",
    "    \"\"\"Algorithme naïf, qui utilise la moyenne empirique.\"\"\"\n",
    "    \n",
    "    def __init__(self, K):\n",
    "        \"\"\"Crée l'instance de l'algorithme.\"\"\"\n",
    "        self.K = K\n",
    "        # Il nous faut de la mémoire interne\n",
    "        self.recompenses = np.zeros(K)  # X_k(t) pour chaque k\n",
    "        self.tirages = np.zeros(K)      # N_k(t) pour chaque k\n",
    "        self.t = 0                      # Temps t interne\n",
    "    \n",
    "    def commence(self):\n",
    "        \"\"\"Initialise l'algorithme : remet à zeros chaque X_k et N_k, et t = 0.\"\"\"\n",
    "        self.recompenses.fill(0)\n",
    "        self.tirages.fill(0)\n",
    "        self.t = 0\n",
    "    \n",
    "    def choix(self):\n",
    "        \"\"\"Si on a vu tous les bras, on prend celui de moyenne empirique la plus grande.\"\"\"\n",
    "        # 1er cas : il y a encore des bras qu'on a jamais vu\n",
    "        if np.min(self.tirages) == 0:\n",
    "            k = np.min(np.where(self.tirages == 0)[0])\n",
    "        # 2nd cas : tous les bras ont été essayé\n",
    "        else:\n",
    "            # Notez qu'on aurait pu ne stocker que ce vecteur moyennes_empiriques\n",
    "            moyennes_empiriques = self.recompenses / self.tirages\n",
    "            k = np.argmax(moyennes_empiriques)\n",
    "        self.t += 1      # Inutile ici\n",
    "        return k\n",
    "        \n",
    "    def recompense(self, k, r):\n",
    "        \"\"\"Donne une récompense r tirée sur le bras k à l'algorithme : met à jour les deux vecteurs internes.\"\"\"\n",
    "        self.recompenses[k] += r\n",
    "        self.tirages[k] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Approche fréquentiste, UCB1, \"Upper Confidence Bound\"\n",
    "\n",
    "Il s'agit d'une amélioration de l'algorithme précédent, où on utilise un autre *indice*.\n",
    "\n",
    "Au lieu d'utiliser la moyenne empirique $g_k(t) = \\widehat{\\mu_k}(t) = \\frac{X_k(t)}{N_k(t)}$ et $A(t) = \\arg\\max_k  g_k(t)$, on utilise une borne supérieure d'un intervalle de confiance autour de cette moyenne :\n",
    "$$g'_k(t) = \\widehat{\\mu_k}(t) + \\sqrt{\\alpha \\frac{\\log t}{N_k(t)}}.$$\n",
    "Et cet *indice* est toujours utilisé pour décider le bras à essayer à chaque instant :\n",
    "$$A^{\\mathrm{UCB}1}(t) = \\arg\\max_k g'_k(t).$$\n",
    "\n",
    "Il faut une constante $\\alpha \\geq 0$, qu'on choisira $\\alpha \\geq \\frac12$ pour avoir des performances raisonnables. $\\alpha$ contrôle le compromis entre *exploitation* et *exploration*, et ne doit pas être trop grand. $\\alpha = 1$ est un bon choix par défaut.\n",
    "\n",
    "> On va gagner du temps en *héritant* de la classe `MoyenneEmpirique` précédente. Ça permet de ne pas réécrire les méthodes qui sont déjà bien écrites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UCB1(MoyenneEmpirique):\n",
    "    \"\"\"Algorithme UCB1.\"\"\"\n",
    "    \n",
    "    def __init__(self, K, alpha=1):\n",
    "        \"\"\"Crée l'instance de l'algorithme. Par défaut, alpha=1.\"\"\"\n",
    "        super(UCB1, self).__init__(K)  # On laisse la classe mère faire le travaille\n",
    "        assert alpha >= 0, \"Erreur : alpha doit etre >= 0.\"\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def choix(self):\n",
    "        \"\"\"Si on a vu tous les bras, on prend celui de moyenne empirique la plus grande.\"\"\"\n",
    "        self.t += 1      # Nécessaire ici\n",
    "        # 1er cas : il y a encore des bras qu'on a jamais vu\n",
    "        if np.min(self.tirages) == 0:\n",
    "            k = np.min(np.where(self.tirages == 0)[0])\n",
    "        # 2nd cas : tous les bras ont été essayé\n",
    "        else:\n",
    "            # Notez qu'on aurait pu ne stocker que ce vecteur moyennes_empiriques\n",
    "            moyennes_empiriques = self.recompenses / self.tirages\n",
    "            ucb = np.sqrt(self.alpha * np.log(self.t) / np.log(self.tirages))\n",
    "            indices = moyennes_empiriques + ucb\n",
    "            k = np.argmax(indices)\n",
    "        return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Approche bayésienne, Thompson Sampling\n",
    "\n",
    "[Ce petit article](http://chercheurs.lille.inria.fr/ekaufman/Matapli_Kaufmann.pdf) explique très bien l'approche bayésienne.\n",
    "\n",
    "On a besoin de savoir manipuler des posteriors, qui seront les posteriors conjugués des distributions des bras.\n",
    "\n",
    "Pour des bras de Bernoulli, le posterior conjugué associé est une loi Beta, notée $\\mathrm{Beta}(\\alpha,\\beta)$ pour deux paramètres $\\alpha,\\beta > 0$.\n",
    "\n",
    "- Les posteriors sont initialisés à $\\mathrm{Beta}(1, 1) = U([0,1])$, c'est-à-dire qu'on met un a priori uniforme sur les $\\mu_k$, comme on ne connaît que $\\mu_k \\in [0,1]$.\n",
    "- Comme les *observations* sont binaires, $r_k(t) \\in \\{0,1\\}$, les paramètres $\\alpha$,$\\beta$ restent entiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import beta\n",
    "\n",
    "class Beta():\n",
    "    \"\"\"Posteriors d'expériences de Bernoulli.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.N = [1, 1]\n",
    "\n",
    "    def reinitialise(self):\n",
    "        self.N = [1, 1]\n",
    "\n",
    "    def echantillon(self):\n",
    "        \"\"\"Un échantillon aléatoire de ce posterior Beta.\"\"\"\n",
    "        return beta(self.N[1], self.N[0])\n",
    "\n",
    "    def observe(self, obs):\n",
    "        \"\"\"Ajoute une nouvelle observation. Si 'obs'=1, augmente alpha, sinon si 'obs'=0, augmente beta.\"\"\"\n",
    "        self.N[int(obs)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dès qu'on sait manipuler ces postériors Beta, on peut implémenter rapidement le dernier algorithme, Thompson Sampling.\n",
    "\n",
    "Les paramètres du posterior sur $\\mu_k$, i.e., $\\alpha_k(t)$,$\\beta_k(t)$ seront mis à jour à chaque étape pour compter le nombre d'observations réussies et échouées :\n",
    "$$ \\alpha_k(t) = 1 + X_k(t) \\\\ \\beta_k(t) = 1 + N_k(t) - X_k(t).$$\n",
    "\n",
    "La moyenne empirique estimant $\\mu_k$ sera, à l'instant $t$,\n",
    "$$ \\widetilde{\\mu_k}(t) = \\frac{\\alpha_k(t)}{\\alpha_k(t) + \\beta_k(t)} = \\frac{1 + X_k(t)}{2 + N_k(t)} \\simeq \\frac{X_k(t)}{N_k(t)}.$$\n",
    "\n",
    "La différence avec UCB1 est que la prise de décision de Thompson Sampling se fait sur un indice, tiré aléatoirement selon les posteriors.\n",
    "C'est une *politique d'indice randomisée*.\n",
    "\n",
    "D'un point de vue bayésien, un *modèle* est tiré selon les posteriors, puis on joue selon le meilleur modèle :\n",
    "$$ g''_k(t) \\sim \\mathrm{Beta}(\\alpha_k(t), \\beta_k(t)) \\\\ A^{\\mathrm{TS}}(t) = \\arg\\max_k g''_k(t). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ThompsonSampling(MoyenneEmpirique):\n",
    "    \"\"\"Algorithme Thompson Sampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, K, posterior=Beta):\n",
    "        \"\"\"Crée l'instance de l'algorithme. Par défaut, alpha=1.\"\"\"\n",
    "        self.K = K\n",
    "        # On créé K posteriors\n",
    "        self.posteriors = [posterior() for k in range(K)]\n",
    "    \n",
    "    def commence(self):\n",
    "        \"\"\"Réinitialise les K posteriors.\"\"\"\n",
    "        for posterior in self.posteriors:\n",
    "            posterior.reinitialise()\n",
    "    \n",
    "    def choix(self):\n",
    "        \"\"\"On tire K modèles depuis les posteriors, et on joue dans le meilleur.\"\"\"\n",
    "        moyennes_estimees = [posterior.echantillon() for posterior in self.posteriors]\n",
    "        k = np.argmax(moyennes_estimees)\n",
    "        return k\n",
    "\n",
    "    def recompense(self, k, r):\n",
    "        \"\"\"Observe cette récompense r sur le bras k en mettant à jour le kième posterior.\"\"\"\n",
    "        self.posteriors[k].observe(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exemples de simulations\n",
    "\n",
    "On va comparer, sur deux problèmes, les 4 algorithmes définis plus haut.\n",
    "\n",
    "Les problèmes sont caractérisés par les moyennes des bras de Bernoulli, $\\boldsymbol{\\mu} = [\\mu_1,\\dots,\\mu_K]$, et on les suppose ordonnées par ordre décroissant : $\\mu_1 > \\mu_2 \\ge \\dots \\ge \\mu_K$.\n",
    "\n",
    "On affichera plusieurs choses, dans des graphiques au cours du temps $t = 0, \\dots, T$ pour un horizon $T = 5000$ étapes :\n",
    "\n",
    "- leurs *taux de sélection* du meilleur bras $k^*$, (qui sera toujours $\\mu_1$ le premier bras), i.e., $N_k(t) / t$ en $\\%$,\n",
    "- leurs *récompenses* accumulées, i.e., $X_k(t)$,\n",
    "- les *récompenses moyennes estimées* de chaque bras, i.e., $\\widehat{\\mu_k}(t) = \\frac{X_k(t)}{N_k(t)}$,\n",
    "- et enfin leurs *regret*. Cette notion est moins triviale, mais pour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour l'affichage\n",
    "\n",
    "On définit 4 fonctions d'affichage pour ces quantités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affiche_selections(kstar, choix, noms):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier problème, à 3 bras\n",
    "On reprend le problème donné plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5000\n",
    "mus = [0.1, 0.5, 0.9]\n",
    "bras = [ Bernoulli(mu) for mu in mus ]\n",
    "K = len(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " [0.1, 0.5, 0.9],\n",
       " [<__main__.Bernoulli at 0x7f58f7eabeb8>,\n",
       "  <__main__.Bernoulli at 0x7f58f7eabf28>,\n",
       "  <__main__.Bernoulli at 0x7f58f7eabf60>],\n",
       " 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon, mus, bras, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.ChoixUniforme at 0x7f58f7eabe48>,\n",
       " <__main__.MoyenneEmpirique at 0x7f58f7eabc18>,\n",
       " <__main__.UCB1 at 0x7f58f7eabc50>,\n",
       " <__main__.ThompsonSampling at 0x7f58f7eb2048>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithmes = [ChoixUniforme(K), MoyenneEmpirique(K), UCB1(K, alpha=1), ThompsonSampling(K)]\n",
    "algorithmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les légendes, on a besoin des noms des algorithmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noms = [\"ChoixUniforme\", \"MoyenneEmpirique\", \"UCB1(alpha=1)\", \"ThompsonSampling\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut commencer la simulation, pour chaque algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "N = len(algorithmes)\n",
    "recompenses, choix = np.zeros((N, horizon)), np.zeros((N, horizon))\n",
    "\n",
    "for i, alg in enumerate(algorithmes):\n",
    "    rec, ch = simulation(bras, alg, horizon)\n",
    "    recompenses[i] = rec\n",
    "    choix[i] = ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.,  1., ...,  1.,  1.,  0.],\n",
       "        [ 0.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  1., ...,  1.,  1.,  1.],\n",
       "        [ 0.,  1.,  1., ...,  1.,  1.,  1.]]),\n",
       " array([[ 0.,  1.,  2., ...,  1.,  2.,  2.],\n",
       "        [ 0.,  1.,  2., ...,  2.,  2.,  2.],\n",
       "        [ 0.,  1.,  2., ...,  2.,  2.,  2.],\n",
       "        [ 1.,  2.,  2., ...,  2.,  2.,  2.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recompenses, choix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second problème, à 10 bras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "Merci d'avoir lu jusqu'ici.\n",
    "\n",
    "> Pour plus de détails, je recommande de lire en détails [ce petit article, datant de 2017, en français, écrit par Émilie Kaufmann](http://chercheurs.lille.inria.fr/ekaufman/Matapli_Kaufmann.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "346px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
