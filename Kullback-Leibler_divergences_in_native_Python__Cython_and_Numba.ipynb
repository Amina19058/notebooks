{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#KL-divergences-and-KL-UCB-indexes,-in-naive-Python\" data-toc-modified-id=\"KL-divergences-and-KL-UCB-indexes,-in-naive-Python-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>KL divergences and KL-UCB indexes, in naive Python</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli-distributions\" data-toc-modified-id=\"Bernoulli-distributions-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Bernoulli distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial-distributions\" data-toc-modified-id=\"Binomial-distributions-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson-distributions\" data-toc-modified-id=\"Poisson-distributions-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Poisson distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential-distributions\" data-toc-modified-id=\"Exponential-distributions-214\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Exponential distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma-distributions\" data-toc-modified-id=\"Gamma-distributions-215\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Gamma distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial-distributions\" data-toc-modified-id=\"Negative-binomial-distributions-216\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Negative binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian-distributions\" data-toc-modified-id=\"Gaussian-distributions-217\"><span class=\"toc-item-num\">2.1.7&nbsp;&nbsp;</span>Gaussian distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generic-KL-UCB-indexes,-with-a-bisection-search\" data-toc-modified-id=\"Generic-KL-UCB-indexes,-with-a-bisection-search-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Generic KL-UCB indexes, with a bisection search</a></div><div class=\"lev2 toc-item\"><a href=\"#Distribution-specific-KL-UCB-indexes\" data-toc-modified-id=\"Distribution-specific-KL-UCB-indexes-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Distribution-specific KL-UCB indexes</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-233\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-234\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev3 toc-item\"><a href=\"#Others\" data-toc-modified-id=\"Others-235\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Others</a></div><div class=\"lev1 toc-item\"><a href=\"#With-Numba\" data-toc-modified-id=\"With-Numba-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>With Numba</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli-distributions\" data-toc-modified-id=\"Bernoulli-distributions-311\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Bernoulli distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial-distributions\" data-toc-modified-id=\"Binomial-distributions-312\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson-distributions\" data-toc-modified-id=\"Poisson-distributions-313\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Poisson distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential-distributions\" data-toc-modified-id=\"Exponential-distributions-314\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Exponential distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma-distributions\" data-toc-modified-id=\"Gamma-distributions-315\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Gamma distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial-distributions\" data-toc-modified-id=\"Negative-binomial-distributions-316\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Negative binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian-distributions\" data-toc-modified-id=\"Gaussian-distributions-317\"><span class=\"toc-item-num\">3.1.7&nbsp;&nbsp;</span>Gaussian distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generic-KL-UCB-indexes,-with-a-bisection-search\" data-toc-modified-id=\"Generic-KL-UCB-indexes,-with-a-bisection-search-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generic KL-UCB indexes, with a bisection search</a></div><div class=\"lev2 toc-item\"><a href=\"#Distribution-specific-KL-UCB-indexes\" data-toc-modified-id=\"Distribution-specific-KL-UCB-indexes-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Distribution-specific KL-UCB indexes</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-331\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-332\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-333\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-334\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev1 toc-item\"><a href=\"#With-Cython\" data-toc-modified-id=\"With-Cython-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>With Cython</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli-distributions\" data-toc-modified-id=\"Bernoulli-distributions-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Bernoulli distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial-distributions\" data-toc-modified-id=\"Binomial-distributions-412\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson-distributions\" data-toc-modified-id=\"Poisson-distributions-413\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Poisson distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential-distributions\" data-toc-modified-id=\"Exponential-distributions-414\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Exponential distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma-distributions\" data-toc-modified-id=\"Gamma-distributions-415\"><span class=\"toc-item-num\">4.1.5&nbsp;&nbsp;</span>Gamma distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial-distributions\" data-toc-modified-id=\"Negative-binomial-distributions-416\"><span class=\"toc-item-num\">4.1.6&nbsp;&nbsp;</span>Negative binomial distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian-distributions\" data-toc-modified-id=\"Gaussian-distributions-417\"><span class=\"toc-item-num\">4.1.7&nbsp;&nbsp;</span>Gaussian distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generic-KL-UCB-indexes,-with-a-bisection-search\" data-toc-modified-id=\"Generic-KL-UCB-indexes,-with-a-bisection-search-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Generic KL-UCB indexes, with a bisection search</a></div><div class=\"lev1 toc-item\"><a href=\"#Tests-and-benchmarks\" data-toc-modified-id=\"Tests-and-benchmarks-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Tests and benchmarks</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-divergences\" data-toc-modified-id=\"KL-divergences-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>KL divergences</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-511\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Binomial\" data-toc-modified-id=\"Binomial-512\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Binomial</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-513\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-514\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev3 toc-item\"><a href=\"#Gamma\" data-toc-modified-id=\"Gamma-515\"><span class=\"toc-item-num\">5.1.5&nbsp;&nbsp;</span>Gamma</a></div><div class=\"lev3 toc-item\"><a href=\"#Negative-binomial\" data-toc-modified-id=\"Negative-binomial-516\"><span class=\"toc-item-num\">5.1.6&nbsp;&nbsp;</span>Negative binomial</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-517\"><span class=\"toc-item-num\">5.1.7&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev2 toc-item\"><a href=\"#KL-UCB-indexes\" data-toc-modified-id=\"KL-UCB-indexes-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>KL-UCB indexes</a></div><div class=\"lev3 toc-item\"><a href=\"#Gaussian\" data-toc-modified-id=\"Gaussian-521\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Gaussian</a></div><div class=\"lev3 toc-item\"><a href=\"#Bernoulli\" data-toc-modified-id=\"Bernoulli-522\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Bernoulli</a></div><div class=\"lev3 toc-item\"><a href=\"#Poisson\" data-toc-modified-id=\"Poisson-523\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Poisson</a></div><div class=\"lev3 toc-item\"><a href=\"#Exponential\" data-toc-modified-id=\"Exponential-524\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span>Exponential</a></div><div class=\"lev1 toc-item\"><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></div><div class=\"lev2 toc-item\"><a href=\"#Take-away-messages\" data-toc-modified-id=\"Take-away-messages-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Take away messages</a></div><div class=\"lev2 toc-item\"><a href=\"#Using-Cython-for-real-?\" data-toc-modified-id=\"Using-Cython-for-real-?-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Using Cython <em>for real</em> ?</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Introduction\n",
    "\n",
    "In this small notebook, I implement various [Kullback-Leibler divergence functions](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), in [Python](https://www.python.org/), using different approaches: naive Python, and using Numba and Cython.\n",
    "\n",
    "I also implement KL-UCB indexes, in the three approaches, and finally I present some basic benchmarks to compare the time and memory efficiency of the different approaches, for each function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Lilian Besson (Naereen) \n",
      "\n",
      "CPython 3.6.3\n",
      "IPython 6.3.1\n",
      "\n",
      "numpy 1.14.2\n",
      "numba 0.37.0\n",
      "\n",
      "compiler   : GCC 7.2.0\n",
      "system     : Linux\n",
      "release    : 4.13.0-38-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 06833391fef4f12f207a3fbec76bbc37ce81c6ec\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -a \"Lilian Besson (Naereen)\" -p numpy,numba -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# KL divergences and KL-UCB indexes, in naive Python\n",
    "\n",
    "I will copy and paste parts of [this file](https://github.com/SMPyBandits/SMPyBandits/blob/master/SMPyBandits/Policies/kullback.py) from my [SMPyBandits](https://github.com/SMPyBandits/SMPyBandits/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will include docstrings and examples only for the naive implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klBern(x, y):\n",
    "    r\"\"\" Kullback-Leibler divergence for Bernoulli distributions. https://en.wikipedia.org/wiki/Bernoulli_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathcal{B}(x), \\mathcal{B}(y)) = x \\log(\\frac{x}{y}) + (1-x) \\log(\\frac{1-x}{1-y}).\"\"\"\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.7577796618689758"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.7577796618689758"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.020135513550688863"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.503217453131898"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34.53957599234081"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klBern(0.5, 0.5)\n",
    "klBern(0.1, 0.9)\n",
    "klBern(0.9, 0.1)\n",
    "klBern(0.4, 0.5)\n",
    "klBern(0.01, 0.99)\n",
    "klBern(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klBin(x, y, n):\n",
    "    r\"\"\" Kullback-Leibler divergence for Binomial distributions. https://math.stackexchange.com/questions/320399/kullback-leibner-divergence-of-binomial-distributions\n",
    "\n",
    "    - It is simply the n times :func:`klBern` on x and y.\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathrm{Bin}(x, n), \\mathrm{Bin}(y, n)) = n \\times \\left(x \\log(\\frac{x}{y}) + (1-x) \\log(\\frac{1-x}{1-y}) \\right).\n",
    "\n",
    "    .. warning:: The two distributions must have the same parameter n, and x, y are p, q in (0, 1).\n",
    "    \"\"\"\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return n * (x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17.57779661868976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17.57779661868976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.20135513550688863"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45.03217453131897"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "345.3957599234081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klBin(0.5, 0.5, 10)\n",
    "klBin(0.1, 0.9, 10)\n",
    "klBin(0.9, 0.1, 10)\n",
    "klBin(0.4, 0.5, 10)\n",
    "klBin(0.01, 0.99, 10)\n",
    "klBin(0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klPoisson(x, y):\n",
    "    r\"\"\" Kullback-Leibler divergence for Poison distributions. https://en.wikipedia.org/wiki/Poisson_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathrm{Poisson}(x), \\mathrm{Poisson}(y)) = y - x + x \\times \\log(\\frac{x}{y}).\n",
    "    \"\"\"\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * np.log(x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3862943611198906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9205584583201643"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2739075652893146"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33.538776394910684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klPoisson(3, 3)\n",
    "klPoisson(2, 1)\n",
    "klPoisson(1, 2)\n",
    "klPoisson(3, 6)\n",
    "klPoisson(6, 8)\n",
    "klPoisson(1, 0)\n",
    "klPoisson(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klExp(x, y):\n",
    "    r\"\"\" Kullback-Leibler divergence for exponential distributions. https://en.wikipedia.org/wiki/Exponential_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathrm{KL}(\\mathrm{Exp}(x), \\mathrm{Exp}(y)) = \\begin{cases}\n",
    "        \\frac{x}{y} - 1 - \\log(\\frac{x}{y}) & \\text{if} x > 0, y > 0\\\\\n",
    "        +\\infty & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "    \"\"\"\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - np.log(x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0376820724517809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klExp(3, 3)\n",
    "klExp(3, 6)\n",
    "klExp(1, 2)\n",
    "klExp(2, 1)\n",
    "klExp(4, 2)\n",
    "klExp(6, 8)\n",
    "klExp(-3, 2)\n",
    "klExp(3, -2)\n",
    "klExp(-3, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klGamma(x, y, a=1):\n",
    "    r\"\"\" Kullback-Leibler divergence for gamma distributions. https://en.wikipedia.org/wiki/Gamma_distribution#Kullback.E2.80.93Leibler_divergence\n",
    "\n",
    "    - It is simply the a times :func:`klExp` on x and y.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathrm{KL}(\\Gamma(x, a), \\Gamma(y, a)) = \\begin{cases}\n",
    "        a \\times \\left( \\frac{x}{y} - 1 - \\log(\\frac{x}{y}) \\right) & \\text{if} x > 0, y > 0\\\\\n",
    "        +\\infty & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "\n",
    "    .. warning:: The two distributions must have the same parameter a.\n",
    "    \"\"\"\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return a * (x / y - 1 - np.log(x / y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1931471805599453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3068528194400547"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0376820724517809"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klGamma(3, 3)\n",
    "klGamma(3, 6)\n",
    "klGamma(1, 2)\n",
    "klGamma(2, 1)\n",
    "klGamma(4, 2)\n",
    "klGamma(6, 8)\n",
    "klGamma(-3, 2)\n",
    "klGamma(3, -2)\n",
    "klGamma(-3, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klNegBin(x, y, r=1):\n",
    "    r\"\"\" Kullback-Leibler divergence for negative binomial distributions. https://en.wikipedia.org/wiki/Negative_binomial_distribution\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\mathrm{NegBin}(x, r), \\mathrm{NegBin}(y, r)) = r \\times \\log((r + x) / (r + y)) - x \\times \\log(y \\times (r + x) / (x \\times (r + y))).\n",
    "\n",
    "    .. warning:: The two distributions must have the same parameter r.\n",
    "    \"\"\"\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return r * np.log((r + x) / (r + y)) - x * np.log(y * (r + x) / (x * (r + y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.7116117934648849"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0321564902394043"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.13065314341785483"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.7173536633057466"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34.53957599234081"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.8329919030334189"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.9148905602182661"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.332552851091954"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.15457261175809217"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.8362571425112515"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klNegBin(0.5, 0.5)\n",
    "klNegBin(0.1, 0.9)\n",
    "klNegBin(0.9, 0.1)\n",
    "klNegBin(0.4, 0.5)\n",
    "klNegBin(0.01, 0.99)\n",
    "klBern(0, 1)\n",
    "klNegBin(0.5, 0.5, r=2)\n",
    "klNegBin(0.1, 0.9, r=2)\n",
    "klNegBin(0.1, 0.9, r=4)\n",
    "klNegBin(0.9, 0.1, r=2)\n",
    "klNegBin(0.4, 0.5, r=2)\n",
    "klNegBin(0.01, 0.99, r=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klGauss(x, y, sig2x=0.25, sig2y=None):\n",
    "    r\"\"\" Kullback-Leibler divergence for Gaussian distributions of means ``x`` and ``y`` and variances ``sig2x`` and ``sig2y``, :math:`\\nu_1 = \\mathcal{N}(x, \\sigma_x^2)` and :math:`\\nu_2 = \\mathcal{N}(y, \\sigma_x^2)`:\n",
    "\n",
    "    .. math:: \\mathrm{KL}(\\nu_1, \\nu_2) = \\frac{(x - y)^2}{2 \\sigma_y^2} + \\frac{1}{2}\\left( \\frac{\\sigma_x^2}{\\sigma_y^2} - 1 \\log\\left(\\frac{\\sigma_x^2}{\\sigma_y^2}\\right) \\right).\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Normal_distribution#Other_properties\n",
    "\n",
    "    - By default, sig2y is assumed to be sig2x (same variance).\n",
    "    \"\"\"\n",
    "    if sig2y is None or - eps < (sig2y - sig2x) < eps:\n",
    "        return (x - y) ** 2 / (2. * sig2x)\n",
    "    else:\n",
    "        return (x - y) ** 2 / (2. * sig2y) + 0.5 * ((sig2x/sig2y)**2 - 1 - np.log(sig2x/sig2y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.028426409720027357"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2243971805599453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1534264097200273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9715735902799727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7243971805599453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.1534264097200273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9715735902799727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7243971805599453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.1534264097200273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klGauss(3, 3)\n",
    "klGauss(3, 6)\n",
    "klGauss(1, 2)\n",
    "klGauss(2, 1)\n",
    "klGauss(4, 2)\n",
    "klGauss(6, 8)\n",
    "klGauss(-3, 2)\n",
    "klGauss(3, -2)\n",
    "klGauss(-3, -2)\n",
    "klGauss(3, 2)\n",
    "klGauss(3, 3, sig2x=10)\n",
    "klGauss(3, 6, sig2x=10)\n",
    "klGauss(1, 2, sig2x=10)\n",
    "klGauss(2, 1, sig2x=10)\n",
    "klGauss(4, 2, sig2x=10)\n",
    "klGauss(6, 8, sig2x=10)\n",
    "klGauss(0, 0, sig2x=0.25, sig2y=0.5)\n",
    "klGauss(0, 0, sig2x=0.25, sig2y=1.0)\n",
    "klGauss(0, 0, sig2x=0.5, sig2y=0.25)\n",
    "klGauss(0, 1, sig2x=0.25, sig2y=0.5)\n",
    "klGauss(0, 1, sig2x=0.25, sig2y=1.0)\n",
    "klGauss(0, 1, sig2x=0.5, sig2y=0.25)\n",
    "klGauss(1, 0, sig2x=0.25, sig2y=0.5)\n",
    "klGauss(1, 0, sig2x=0.25, sig2y=1.0)\n",
    "klGauss(1, 0, sig2x=0.5, sig2y=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic KL-UCB indexes, with a bisection search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucb(x, d, kl, upperbound, lowerbound=float('-inf'), precision=1e-6, max_iterations=50):\n",
    "    \"\"\" The generic KL-UCB index computation.\n",
    "\n",
    "    - x: value of the cum reward,\n",
    "    - d: upper bound on the divergence,\n",
    "    - kl: the KL divergence to be used (:func:`klBern`, :func:`klGauss`, etc),\n",
    "    - upperbound, lowerbound=float('-inf'): the known bound of the values x,\n",
    "    - precision=1e-6: the threshold from where to stop the research,\n",
    "    - max_iterations: max number of iterations of the loop (safer to bound it to reduce time complexity).\n",
    "\n",
    "    .. note:: It uses a **bisection search**, and one call to ``kl`` for each step of the bisection search.\n",
    "    \"\"\"\n",
    "    value = max(x, lowerbound)\n",
    "    u = upperbound\n",
    "    _count_iteration = 0\n",
    "    while _count_iteration < max_iterations and u - value > precision:\n",
    "        _count_iteration += 1\n",
    "        m = (value + u) / 2.\n",
    "        if kl(x, m) > d:\n",
    "            u = m\n",
    "        else:\n",
    "            value = m\n",
    "    return (value + u) / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `klucbBern`, the two steps are to first compute an upperbound (as precise as possible) and the compute the kl-UCB index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944824218750001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998048"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = 0.9, 0.2\n",
    "upperbound = 1\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-3, max_iterations=10)\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-6, max_iterations=10)\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-3, max_iterations=50)\n",
    "klucb(x, d, klBern, upperbound, lowerbound=0, precision=1e-6, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-specific KL-UCB indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucbGauss(x, d, sig2x=0.25, precision=0.):\n",
    "    \"\"\" KL-UCB index computation for Gaussian distributions.\n",
    "\n",
    "    - Note that it does not require any search.\n",
    "\n",
    "    .. warning:: it works only if the good variance constant is given.\n",
    "    \"\"\"\n",
    "    return x + np.sqrt(2 * sig2x * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.416227766016838"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.816227766016838"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.216227766016838"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.547213595499958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7708203932499369"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9472135954999579"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.170820393249937"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.347213595499958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.570820393249937"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbGauss(0.1, 0.2)\n",
    "klucbGauss(0.5, 0.2)\n",
    "klucbGauss(0.9, 0.2)\n",
    "klucbGauss(0.1, 0.4)\n",
    "klucbGauss(0.1, 0.9)\n",
    "klucbGauss(0.5, 0.4)\n",
    "klucbGauss(0.5, 0.9)\n",
    "klucbGauss(0.9, 0.4)\n",
    "klucbGauss(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucbBern(x, d, precision=1e-6):\n",
    "    \"\"\" KL-UCB index computation for Bernoulli distributions, using :func:`klucb`.\"\"\"\n",
    "    upperbound = min(1., klucbGauss(x, d, sig2x=0.25))  # variance 1/4 for [0,1] bounded distributions\n",
    "    # upperbound = min(1., klucbPoisson(x, d))  # also safe, and better ?\n",
    "    return klucb(x, d, klBern, upperbound, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37839145109809247"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7870889692292777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998048"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5194755673450786"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7347148310932183"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.871035844022684"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9568095207214355"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9992855072021485"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9999950408935546"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbBern(0.1, 0.2)\n",
    "klucbBern(0.5, 0.2)\n",
    "klucbBern(0.9, 0.2)\n",
    "klucbBern(0.1, 0.4)\n",
    "klucbBern(0.1, 0.9)\n",
    "klucbBern(0.5, 0.4)\n",
    "klucbBern(0.5, 0.9)\n",
    "klucbBern(0.9, 0.4)\n",
    "klucbBern(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klucbPoisson(x, d, precision=1e-6):\n",
    "    \"\"\" KL-UCB index computation for Poisson distributions, using :func:`klucb`.\"\"\"\n",
    "    upperbound = x + d + np.sqrt(d * d + 2 * x * d)  # looks safe, to check: left (Gaussian) tail of Poisson dev\n",
    "    return klucb(x, d, klPoisson, upperbound, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45052392780119604"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0893765430263218"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.6401128559741487"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6936844019642616"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.2527967047658155"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4229339603816749"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.122985165630671"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.033691887156203"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.8315738094979777"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbPoisson(0.1, 0.2)\n",
    "klucbPoisson(0.5, 0.2)\n",
    "klucbPoisson(0.9, 0.2)\n",
    "klucbPoisson(0.1, 0.4)\n",
    "klucbPoisson(0.1, 0.9)\n",
    "klucbPoisson(0.5, 0.4)\n",
    "klucbPoisson(0.5, 0.9)\n",
    "klucbPoisson(0.9, 0.4)\n",
    "klucbPoisson(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def klucbExp(x, d, precision=1e-6):\n",
    "    \"\"\" KL-UCB index computation for exponential distributions, using :func:`klucb`.\"\"\"\n",
    "    if d < 0.77:  # XXX where does this value come from?\n",
    "        upperbound = x / (1 + 2. / 3 * d - np.sqrt(4. / 9 * d * d + 2 * d))\n",
    "        # safe, klexp(x,y) >= e^2/(2*(1-2e/3)) if x=y(1-e)\n",
    "    else:\n",
    "        upperbound = x * np.exp(d + 1)\n",
    "    if d > 1.61:  # XXX where does this value come from?\n",
    "        lowerbound = x * np.exp(d)\n",
    "    else:\n",
    "        lowerbound = x / (1 + d - np.sqrt(d * d + 2 * d))\n",
    "    return klucb(x, d, klGamma, upperbound, lowerbound, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20274118449172676"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.013706285168157"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.8246716397412546"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2857928251730546"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5590884945251575"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.428962647183463"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.7954420946912126"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.572132498767508"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.031795430303065"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klucbExp(0.1, 0.2)\n",
    "klucbExp(0.5, 0.2)\n",
    "klucbExp(0.9, 0.2)\n",
    "klucbExp(0.1, 0.4)\n",
    "klucbExp(0.1, 0.9)\n",
    "klucbExp(0.5, 0.4)\n",
    "klucbExp(0.5, 0.9)\n",
    "klucbExp(0.9, 0.4)\n",
    "klucbExp(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others\n",
    "We could do the same for more distributions, but that's enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# With Numba\n",
    "\n",
    "It will be *exactly* the same code as above, except that the [`numba.jit`](http://numba.pydata.org/numba-doc/latest/user/jit.html) decorator will be used for each functions, to let [numba](http://numba.pydata.org/) *try* to speed up the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As much as possible, one should call `@jit(nopython=True)` to be sure that numba does not fall back silently to naive Python code. With `nopython=True`, any call to the generated function will fail if the compilation could not succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klBern_numba(x, y):\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klBin_numba(x, y, n):\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return n * (x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klPoisson_numba(x, y):\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * np.log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klExp_numba(x, y):\n",
    "    if x <= 0 or y <= 0:\n",
    "        return inf\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - np.log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klGamma_numba(x, y, a=1):\n",
    "    if x <= 0 or y <= 0:\n",
    "        return inf\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return a * (x / y - 1 - np.log(x / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klNegBin_numba(x, y, r=1):\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return r * np.log((r + x) / (r + y)) - x * np.log(y * (r + x) / (x * (r + y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klGauss_numba(x, y, sig2x=0.25, sig2y=0.25):\n",
    "    if - eps < (sig2y - sig2x) and (sig2y - sig2x) < eps:\n",
    "        return (x - y) ** 2 / (2. * sig2x)\n",
    "    else:\n",
    "        return (x - y) ** 2 / (2. * sig2y) + 0.5 * ((sig2x/sig2y)**2 - 1 - np.log(sig2x/sig2y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic KL-UCB indexes, with a bisection search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucb_numba(x, d, kl, upperbound,\n",
    "                lowerbound=float('-inf'), precision=1e-6, max_iterations=50):\n",
    "    value = max(x, lowerbound)\n",
    "    u = upperbound\n",
    "    _count_iteration = 0\n",
    "    while _count_iteration < max_iterations and u - value > precision:\n",
    "        _count_iteration += 1\n",
    "        m = (value + u) / 2.\n",
    "        if kl(x, m) > d:\n",
    "            u = m\n",
    "        else:\n",
    "            value = m\n",
    "    return (value + u) / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `klucbBern`, the two steps are to first compute an upperbound (as precise as possible) and the compute the kl-UCB index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944824218750001"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998048"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = 0.9, 0.2\n",
    "upperbound = 1\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-3, max_iterations=10)\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-6, max_iterations=10)\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-3, max_iterations=50)\n",
    "klucb_numba(x, d, klBern_numba, upperbound, lowerbound=0, precision=1e-6, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-specific KL-UCB indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def klucbGauss_numba(x, d, sig2x=0.25, precision=0.):\n",
    "    return x + np.sqrt(2 * sig2x * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli\n",
    "\n",
    "Here, the `nopython=True` fails as numba has a hard time typing linked function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucbBern_numba(x, d, precision=1e-6):\n",
    "    upperbound = min(1., klucbGauss_numba(x, d, sig2x=0.25))  # variance 1/4 for [0,1] bounded distributions\n",
    "    # upperbound = min(1., klucbPoisson(x, d))  # also safe, and better ?\n",
    "    return klucb_numba(x, d, klBern_numba, upperbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucbPoisson_numba(x, d, precision=1e-6):\n",
    "    upperbound = x + d + np.sqrt(d * d + 2 * x * d)  # looks safe, to check: left (Gaussian) tail of Poisson dev\n",
    "    return klucb_numba(x, d, klPoisson_numba, upperbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def klucbExp_numba(x, d, precision=1e-6):\n",
    "    if d < 0.77:  # XXX where does this value come from?\n",
    "        upperbound = x / (1 + 2. / 3 * d - np.sqrt(4. / 9 * d * d + 2 * d))\n",
    "        # safe, klexp(x,y) >= e^2/(2*(1-2e/3)) if x=y(1-e)\n",
    "    else:\n",
    "        upperbound = x * np.exp(d + 1)\n",
    "    if d > 1.61:  # XXX where does this value come from?\n",
    "        lowerbound = x * np.exp(d)\n",
    "    else:\n",
    "        lowerbound = x / (1 + d - np.sqrt(d * d + 2 * d))\n",
    "    return klucb_numba(x, d, klGamma_numba, upperbound, lowerbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# With Cython\n",
    "\n",
    "It will be *almost* exactly the same code, by using the [`cython`]() magic to have cells written in [Cython](http://cython.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cell can now be written in Cython.\n",
    "For instance, we can define a simple example function in Python, and then write a Cython version, simply by declaring variables and tagging their types, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_loop(n: int) -> int:\n",
    "    s = 0\n",
    "    for i in range(0, n, 2):\n",
    "        s += i\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def some_loop_cython(int n) -> int:\n",
    "    cdef int s = 0\n",
    "    cdef int i = 0\n",
    "    for i in range(0, n, 2):\n",
    "        s += i\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 µs ± 90.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "14.6 µs ± 528 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "2.21 µs ± 197 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.random.randint(1000)\n",
    "%timeit some_loop(np.random.randint(1000))\n",
    "%timeit some_loop_cython(np.random.randint(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe a large speed-up. But how large? $6$ times or $50$ times?\n",
    "\n",
    "It's really important to include the time taken by the Pseudo-Random Number Generator:\n",
    "\n",
    "- Wrong computation of the speed-up gives about $6$ times faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.606334841628959"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14.6 / 2.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But if we remove the time taken by the PRNG (which takes the same time for both the naive Python and the Cython function), we get a larger speed-up, closer to reality, about $50$ times and not just $6$ times faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.65384615384615"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(14.6 - 1.95) / (2.21 - 1.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klBern_cython(float x, float y) -> float:\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * log(x / y) + (1 - x) * log((1 - x) / (1 - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klBin_cython(float x, float y, int n) -> float:\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return n * (x * log(x / y) + (1 - x) * log((1 - x) / (1 - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klPoisson_cython(float x, float y) -> float:\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klExp_cython(float x, float y) -> float:\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - log(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klGamma_cython(float x, float y, float a=1) -> float:\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return a * (x / y - 1 - log(x / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klNegBin_cython(float x, float y, float r=1) -> float:\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return r * log((r + x) / (r + y)) - x * log(y * (r + x) / (x * (r + y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport log\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "def klGauss_cython(float x, float y, float sig2x=0.25, float sig2y=0.25) -> float:\n",
    "    if - eps < (sig2y - sig2x) < eps:\n",
    "        return (x - y) ** 2 / (2. * sig2x)\n",
    "    else:\n",
    "        return (x - y) ** 2 / (2. * sig2y) + 0.5 * ((sig2x/sig2y)**2 - 1 - log(sig2x/sig2y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic KL-UCB indexes, with a bisection search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these, they need previously defined functions, which have to be rewritten from inside the `cython` cell to be accessible from Cython.\n",
    "To minimize repetitions, I use only one cell to define all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport sqrt, log, exp\n",
    "eps = 1e-15  #: Threshold value: everything in [0, 1] is truncated to [eps, 1 - eps]\n",
    "\n",
    "\n",
    "def klucbGauss_cython(float x, float d, float sig2x=0.25, float precision=0.) -> float:\n",
    "    return x + sqrt(2 * sig2x * d)\n",
    "\n",
    "cdef float klucbGauss_cython_x(float x, float d, float sig2x=0.25, float precision=0.):\n",
    "    return x + sqrt(2 * sig2x * d)\n",
    "\n",
    "\n",
    "def klucb_cython(float x, float d, kl, float upperbound,\n",
    "                 float lowerbound=float('-inf'),\n",
    "                 float precision=1e-6, int max_iterations=50) -> float:\n",
    "    cdef float value = max(x, lowerbound)\n",
    "    cdef float u = upperbound\n",
    "    cdef int _count_iteration = 0\n",
    "    cdef float m = 0\n",
    "    while _count_iteration < max_iterations and u - value > precision:\n",
    "        _count_iteration += 1\n",
    "        m = (value + u) / 2.\n",
    "        if kl(x, m) > d:\n",
    "            u = m\n",
    "        else:\n",
    "            value = m\n",
    "    return (value + u) / 2.\n",
    "\n",
    "\n",
    "cdef float klBern_cython_x(float x, float y):\n",
    "    x = min(max(x, eps), 1 - eps)\n",
    "    y = min(max(y, eps), 1 - eps)\n",
    "    return x * log(x / y) + (1 - x) * log((1 - x) / (1 - y))\n",
    "\n",
    "def klucbBern_cython(float x, float d, float precision=1e-6) -> float:\n",
    "    cdef float upperbound = min(1., klucbGauss_cython_x(x, d, sig2x=0.25))  # variance 1/4 for [0,1] bounded distributions\n",
    "    # upperbound = min(1., klucbPoisson(x, d))  # also safe, and better ?\n",
    "    return klucb_cython(x, d, klBern_cython_x, upperbound, precision)\n",
    "\n",
    "\n",
    "cdef float klPoisson_cython_x(float x, float y):\n",
    "    x = max(x, eps)\n",
    "    y = max(y, eps)\n",
    "    return y - x + x * log(x / y)\n",
    "\n",
    "def klucbPoisson_cython(float x, float d, float precision=1e-6) -> float:\n",
    "    cdef float upperbound = x + d + sqrt(d * d + 2 * x * d)  # looks safe, to check: left (Gaussian) tail of Poisson dev\n",
    "    return klucb_cython(x, d, klPoisson_cython_x, upperbound, precision)\n",
    "\n",
    "\n",
    "cdef float klGamma_cython_x(float x, float y):\n",
    "    if x <= 0 or y <= 0:\n",
    "        return float('+inf')\n",
    "    else:\n",
    "        x = max(x, eps)\n",
    "        y = max(y, eps)\n",
    "        return x / y - 1 - log(x / y)\n",
    "\n",
    "def klucbExp_cython(float x, float d, float precision=1e-6) -> float:\n",
    "    cdef float upperbound = 1\n",
    "    cdef float lowerbound = 0\n",
    "    if d < 0.77:  # XXX where does this value come from?\n",
    "        upperbound = x / (1 + 2. / 3 * d - sqrt(4. / 9 * d * d + 2 * d))\n",
    "        # safe, klexp(x,y) >= e^2/(2*(1-2e/3)) if x=y(1-e)\n",
    "    else:\n",
    "        upperbound = x * exp(d + 1)\n",
    "    if d > 1.61:  # XXX where does this value come from?\n",
    "        lowerbound = x * exp(d)\n",
    "    else:\n",
    "        lowerbound = x / (1 + d - sqrt(d * d + 2 * d))\n",
    "    return klucb_cython(x, d, klGamma_cython_x, upperbound, lowerbound, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for `klucbBern_cython`, the two steps are to first compute an upperbound (as precise as possible) and the compute the kl-UCB index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944823980331421"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.994140625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9944896697998047"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = 0.9, 0.2\n",
    "upperbound = 1\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-3, max_iterations=10)\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-6, max_iterations=10)\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-3, max_iterations=50)\n",
    "klucb_cython(x, d, klBern_cython, upperbound, lowerbound=0, precision=1e-6, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Tests and benchmarks\n",
    "\n",
    "For each of the functions defined in three approaches above, I will do some numerical tests to compare their speed − and memory −  efficiency. Simple.\n",
    "\n",
    "The benchmark will be to test the computation time on random entries.\n",
    "It includes a constant time: creating random values! So I also compare the time to simply generate the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.random\n",
    "rn = lambda: np.random.randint(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705 ns ± 46.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "2.5 µs ± 108 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (r(), r())\n",
    "%timeit (r(), r(), rn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The time to generate random numbers like this is small, but not zero!\n",
    "- Generating a uniform integer, in particular, takes some time (more than 1 µs is not something that can be ignored!).\n",
    "\n",
    "$\\implies$ we will remove this $700$ ns or $2.5$ µs overhead when computing speed-up ratio between naive Python and numb or Cython versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we also need to test that the three versions of each function gives the same results (up-to approximation errors less than \n",
    "$10^{-6}$ (at least))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fs(fs, inputs, tolerance=1e-5, nb_tests=100):\n",
    "    for _ in range(nb_tests):\n",
    "        args = inputs()\n",
    "        ref_f = fs[0]  # Python version\n",
    "        output = ref_f(*args)\n",
    "        for other_f in fs[1:]:\n",
    "            other_output = other_f(*args)\n",
    "            if abs(output) > 1:\n",
    "                rel_diff = (output - other_output) / output\n",
    "            else:\n",
    "                rel_diff = (output - other_output)\n",
    "            assert abs(rel_diff) <= tolerance, \"Error: function {} gave {} and function {} gave {} on inputs {}, and the two outputs are too different.\".format(ref_f, output, other_f, other_output, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klBern, klBern_numba, klBern_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.84 µs ± 38.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980 ns ± 100 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949 ns ± 36.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBern_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $12$ times faster for both Numba and Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.214285714285714"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12.610441767068274"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3840 - 700) / (980 - 700)  # for Python vs numba\n",
    "(3840 - 700) / (949 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klBin, klBin_numba, klBin_cython], lambda: (r(), r(), rn()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.66 µs ± 364 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBin(r(), r(), rn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.53 µs ± 548 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBin_numba(r(), r(), rn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.47 µs ± 222 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klBin_cython(r(), r(), rn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $5$ times faster for both Numba and Cython. Not so great, but still something!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.009708737864078"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.319587628865979"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7660 - 2500) / (3530 - 2500)  # for Python vs numba\n",
    "(7660 - 2500) / (3470 - 2500)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klPoisson, klPoisson_numba, klPoisson_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.58 µs ± 275 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klPoisson(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951 ns ± 22.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klPoisson_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 ns ± 235 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klPoisson_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $7.5$ times faster for both Numba and Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.49003984063745"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.704918032786885"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2580 - 700) / (951 - 700)  # for Python vs numba\n",
    "(2580 - 700) / (944 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klExp, klExp_numba, klExp_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.37 µs ± 96.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klExp(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 ns ± 94.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klExp_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844 ns ± 50.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klExp_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $6$ times faster for Numba and $12$ times faster for Cython.\n",
    "Cython starts to win the race!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.943060498220641"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11.597222222222221"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2370 - 700) / (981 - 700)  # for Python vs numba\n",
    "(2370 - 700) / (844 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klGamma, klGamma_numba, klGamma_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94 µs ± 358 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGamma(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07 µs ± 87 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGamma_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799 ns ± 46 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGamma_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $6$ times faster for Numba, and $22$ times faster for Cython!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.054054054054054"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "22.626262626262626"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2940 - 700) / (1070 - 700)  # for Python vs numba\n",
    "(2940 - 700) / (799 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klNegBin, klNegBin_numba, klNegBin_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.67 µs ± 174 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klNegBin(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13 µs ± 31.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klNegBin_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934 ns ± 33.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klNegBin_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $7$ times faster for Numba and $13$ times faster for Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.906976744186046"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12.692307692307692"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3670 - 700) / (1130 - 700)  # for Python vs numba\n",
    "(3670 - 700) / (934 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klGauss, klGauss_numba, klGauss_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 ns ± 9.18 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGauss(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.4 µs ± 613 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGauss_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703 ns ± 10.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klGauss_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $45$ times faster for Cython, but Numba completely failed here!\n",
    "Why? No idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004903741373047584"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(835 - 700) / (276000 - 700)  # for Python vs numba\n",
    "(835 - 700) / (703 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL-UCB indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klucbGauss, klucbGauss_numba, klucbGauss_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81 µs ± 103 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbGauss(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 µs ± 2.51 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbGauss_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775 ns ± 138 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbGauss_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $15$ times faster for Cython, and one more failure case for Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0378839590443686"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14.8"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1810 - 700) / (30000 - 700)  # for Python vs numba\n",
    "(1810 - 700) / (775 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klucbBern, klucbBern_numba, klucbBern_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.3 µs ± 3.95 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbBern(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 µs ± 7.78 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbBern_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.84 µs ± 156 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbBern_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $15$ times faster for Cython, and one more failure case for Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5534967124925284"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15.0814332247557"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(93300 - 700) / (168000 - 700)  # for Python vs numba\n",
    "(93300 - 700) / (6840 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klucbPoisson, klucbPoisson_numba, klucbPoisson_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.2 µs ± 7.12 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbPoisson(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 µs ± 31.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbPoisson_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6 µs ± 83.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbPoisson_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $18$ times faster for Cython, and one more failure case for Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4418308963763509"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17.82051282051282"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(70200 - 700) / (158000 - 700)  # for Python vs numba\n",
    "(70200 - 700) / (4600 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs([klucbExp, klucbExp_numba, klucbExp_cython], lambda: (r(), r()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.5 µs ± 2.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbExp(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 µs ± 5.23 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbExp_numba(r(), r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53 µs ± 87 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit klucbExp_cython(r(), r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a speed-up ratio of about $17$ times faster for Cython, and one more failure case for Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4459738472126635"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16.919060052219322"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(65500 - 700) / (146000 - 700)  # for Python vs numba\n",
    "(65500 - 700) / (4530 - 700)  # for Python vs Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Conclusion\n",
    "\n",
    "- As expected, both the Numba and Cython versions are *way* faster than the naive Python versions, on very simple functions,\n",
    "- The simpler the function, the closer the speed-up is between Numba and Cython,\n",
    "- Cython always gives the best improvement,\n",
    "- On less simple functions, Numba can fail to produce `nopython` code, and on some examples the `nopython` code can be *slower* than naive Python (like, crazily slower). No idea why, and the point was precisely not to try too much optimizing this use of Numba.\n",
    "- Cython gives speed-up factors typically between $100$ and $12$ times faster than naive Python.\n",
    "\n",
    "## Take away messages\n",
    "The take away messages are the following:\n",
    "\n",
    "1. if your code makes a heavy use of a few small and not-too-complicated functions, it is probably worth using `numba.jit` to speed them up,\n",
    "2. but be careful, and do some basic benchmark on each \"possibly optimized\" function, to check that using Numba actually speeds it up instead of slowing it down!\n",
    "3. if Numba is not enough to speed up your code, try to write a Cython version of the bottleneck functions.\n",
    "\n",
    "## Using Cython *for real* ?\n",
    "My advice for using Cython are the following:\n",
    "\n",
    "1. First try in a notebook, using this [`%%cython` magic is very easy!](https://cython.readthedocs.io/en/latest/src/quickstart/build.html#using-the-jupyter-notebook)\n",
    "2. Then if you are happy about your implementation, save it to a `.pyx` file, and use [`pyximport`](https://cython.readthedocs.io/en/latest/src/userguide/source_files_and_compilation.html#pyximport) from your Python code to automatically compile and import it. It works perfectly fine, believe me!\n",
    "\n",
    "> That's it for today, folks! See [this page](https://github.com/Naereen/notebooks) for other notebooks I wrote recently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "513px",
    "left": "985.125px",
    "right": "20px",
    "top": "96px",
    "width": "246px"
   },
   "toc_section_display": "none",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
